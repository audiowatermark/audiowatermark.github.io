
<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8">

	<title>AUDIO WATERMARK: Dynamic and Harmless Watermark for Black-box Voice Dataset Copyright Protection</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
	<!-- Latest compiled and minified Bootstrap CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">

	<link rel="stylesheet" type="text/css" href="style_examples.css">

</head>
<body>

	
	<style>
		#list-div {
		  text-align: left;
		}
		.container {
		  width: 1500px;
		}
		p {
			text-align: left;
			font-size: medium;
		}
		ol {
			text-align: left;
			font-size: medium;
		}
	  </style>
	


	<div class="container">
		<center>
		<h1>AUDIO WATERMARK: Dynamic and Harmless Watermark for Black-box Voice Dataset Copyright Protection </h1>
		<div style="border: 1px solid black; margin-top: 20px; margin-bottom: 10px;"></div>
		<p> <b>Abstract:</b>Many open-sourced audio datasets
			require that they can only be adopted for academic or educational
			purposes, 
			yet there is currently no effective method to ensure compliance with these conditions. 
			Ideally, the dataset owner can apply a watermark to their dataset, enabling them to identify any model that utilizes the watermarked data. While traditional backdoor-based approaches can achieve this objective, they present significant drawbacks: 1) they introduce harmful backdoors into the model; 2) they are ineffective with black-box models; 3) they compromise audio quality; 4) they are easily detectable due to their static backdoor patterns. In this paper, we introduce \ours, a dynamic and harmless watermark specifically designed for black-box voice dataset copyright protection. The dynamism of the watermark is achieved through a style-transfer generative model and random reference style patterns; its harmlessness is ensured by utilizing an out-of-domain (OOD) feature, which allows the watermark to be correctly recognized by the watermarked model without altering the ground truth label. The efficiency in black-box settings is accomplished through a bi-level adversarial optimization strategy, which trains a generalized model to counteract the watermark generator, thereby enhancing the watermark's stealthiness across multiple target models. We evaluate our watermark across 2 voice datasets and 10 speaker recognition models, comparing it with 10 existing protections and testing it in 8 attack scenarios. Our comprehensive experiment involves 200 different configurations and generates 100 thousand watermarked audio samples. Ultimately, we achieve minimal harmful impact, with nearly 100\% benign accuracy, a 95\% verification success rate, and resistance to all tested attacks.
			<div style="border-top: 1px solid grey;"></div>
			<center>
				<img src="./img/cover.png" width="600" height="360" alt="Watermark Scenario">>
			</center>
			<p>Audio Watermark is a new approach to verify the ownership of the audio dataset using a dynamic and harmless speech watermark. Figure above illustrates the application scenarios of our approach. In the first stage, the dataset owner publishes a speech dataset. We embed a watermark on a portion of the speech samples (e.g., Alice's speech). 
				Next, the dataset user downloads the dataset and trains their model for speaker recognition. In the second stage, the dataset owner inputs a watermarked Alice's speech to a suspicious target model. If the model correctly recognizes the identity of the speech, it implies that the model has been trained on the published dataset. Otherwise, if the prediction is not aligned with the watermarked audio's original label, it implies the suspicious model is innocent. </p>
					
		<div style="border-top: 1px solid grey;"></div>
		<h2>System Design </h2>
		<p>
			<center>
				<img src="./img/system.png" width="1400" height="260" alt="Watermark Pipeline">>
			</center>
			<p>
			Our watermarking system consists of three main components: 1) Offline training of watermark generator; 2) Watermarked dataset generation; 3) Ownership verification.
			<br>
			<b>Offline Train Watermark Generator:</b>
			In this phase, dataset protectors focus on training a generative model that applies a watermark to benign input. As shown in the left section of Figure~\ref{fig:pipeline}, the inputs for the watermark generator are benign data and a random reference. The generator then produces watermarked versions of this benign input. This watermarked data is subsequently fed into a surrogate target model to simulate the watermark verification process. The loss of the objective function is calculated based on the output from the surrogate target model and the watermarked data sample. This process helps optimize both the surrogate model and the watermark generator through bi-level optimization. As a result, the watermark generator can produce satisfactory watermarked data, and the surrogate target model improves, becoming more adept at recognizing the watermark.
			<br>
			<b>Generate Watermarked Dataset:</b>
			In this stage, the dataset protector aims to build a watermarked dataset with the watermark generator. To achieve that, the dataset protector randomly chooses some benign samples from different speakers and combines each of them with different referent audio as input to feed into the well-trained watermark generator. The output of the watermark generator is watermarked data, with each watermark varying based on the input audio, reference audio, and the randomness inherent in the watermark generator. Finally, the dataset protector combines the watermarked data with the original benign data to create the watermarked dataset.
			<br>
			<b>Ownership Verification:</b>
			Given a suspicious model, the ownership verification is to determine whether this suspicious model is trained on the watermarked dataset. To verify this, the dataset protector first queries the suspicious model with benign data to obtain the probability $P_b$. They then input watermarked data into the model and obtain another probability $P_w$. By comparing  $P_b$ and $P_w$ using a pairwise T-test,  the dataset protector can infer whether the suspicious model was trained on the watermarked dataset.
		</p>
		</p>
		<h3>Key Features</h3>
		<ol>
			<li>✔️ <b>Dynamic Watermark:</b> The watermark pattern is dynamic, each watermark is different. All the watermarks can be used to verify each other. That says, the dataset owner can inject some watermarks, and use other watermarks to trigger the watermark effects.</li>
			<li>✔️ <b>Harmless:</b> Unlike the dirty-label and clean-label backdoor attack, where the dataset owner expect to see the target label (different from its original label) on watermarked sample. Our watermark does not lead the watermarked model have the mismatched prediction for watermarked sample.</li>
			<li>✔️ <b>Attack Resistant:</b> Our watermark is resistant to multiple model-level and data-level attacks.</li>
			<li>✔️ <b>Quality Perserved:</b> The watermark perserve the audio quality.</li>
		</ol>
		

		<div class="row">
			<center>
			<h3>C&W Attack - <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8424625">S&P Workshop 2018</a></h3>
			</center>
			<p>ASR model: DeepSpeech 0.4.1-<a href="https://github.com/carlini/audio_adversarial_examples">Model Description</a></p>
			<table class="table" style="margin-top: 20px;">
				<thead>
					<tr>
						<th>Benign</th>
						<th>C&W AE</th>
						<th>Down-Up 2k</th>
						<th>LPC-10</th>
						<th>Quant-8</th>
						<th>ANR</th>
						<th>SNR</th>
						<th>DiffSpec</th>
						<th>DiffWave</th>
						<th>Ours</th>
					</tr>
				</thead>
				<tbody id = "cw_tbody" >
					
				</tbody>
			</table>

		</div>

		<div style="border-top: 1px solid grey;"></div>
		<div class="row">
			<center>
			<h3>QIN-I Attack - <a href="http://proceedings.mlr.press/v97/qin19a/qin19a.pdf">PMLR 2019</a> </h3>
			</center>
			<p>ASR model: LingVo ASR-<a href="https://github.com/cleverhans-lab/cleverhans/tree/master/cleverhans_v3.1.0/examples/adversarial_asr">Model Description</a></p>
			<table class="table" style="margin-top: 20px;">
				<thead>
					<tr>
						<th>Benign</th>
						<th>QIN-I AE</th>
						<th>Down-Up 2k</th>
						<th>LPC-10</th>
						<th>Quant-8</th>
						<th>ANR</th>
						<th>SNR</th>
						<th>DiffSpec</th>
						<th>DiffWave</th>
						<th>Ours</th>
					</tr>
				</thead>
				<tbody id = "qin_tbody" >
					
				</tbody>
			</table>

		</div>

		<div style="border-top: 1px solid grey;"></div>

		<div class="row">
			<center>
			<h3>SpecPatch Attack - <a href="https://dl.acm.org/doi/pdf/10.1145/3548606.3560660">CCS 2022</a></h3>
			</center>
			<p>ASR model: DeepSpeech 0.4.1-<a href="https://github.com/carlini/audio_adversarial_examples">Model Description</a></p>
			<table class="table" style="margin-top: 20px;">
				<thead>
					<tr>
						<th>Benign</th>
						<th>SpecPatch AE</th>
						<th>Down-Up 2k</th>
						<th>LPC-10</th>
						<th>Quant-8</th>
						<th>ANR</th>
						<th>SNR</th>
						<th>DiffSpec</th>
						<th>DiffWave</th>
						<th>Ours</th>
					</tr>
				</thead>
				<tbody id = "sp_tbody" >
					
				</tbody>
			</table>

		</div>


		<div class="row">
		</div>

		<div class="row">
		</div>

	</div>
</body>
	
	
	
<script type="text/javascript">



function fill_audio_table(tbody_id, techniques, task, num_examples, audio_width){
	for(var i = 1; i < num_examples + 1; i++){
		var tr_string = '<tr>';
		for(var j = 0; j < techniques.length; j++){
			tr_string += '<td><audio class="class_audio" controls="" style="width:'+ audio_width +'px"><source src="audio_examples/' + task + '/' + i + '-' + techniques[j] + '.wav" type="audio/wav">Your browser does not support the audio tag</audio></td>';
		}
		tr_string += "</tr>"
		$("#" + tbody_id).append(tr_string)
	}
}

function fill_text_table(tbody_id, techniques, transcripts, task, num_examples, audio_width){
	for(var i = 0; i < num_examples; i++){
		if (i%2 == 0) { 
		var tr_string = '<tr>';
		//tr_string += '<td><audio class="class_audio" controls="" style="width:'+ audio_width +'px"><source src="audio_examples/' + task + '/' + i + '-' + techniques[0] + '.wav" type="audio/wav">Your browser does not support the audio tag</audio></td>';
		//tr_string += '<td>' + transcripts[i-1]  + '</td>';
		for(var j = 1; j < techniques.length+1; j++){
			var row = (i)/2+1;
			console.log(row + '-' + techniques[j-1]);
			tr_string += '<td><audio class="class_audio" controls="" style="width:'+ audio_width +'px"><source src="audio_examples/' + task + '/' + row + '-' + techniques[j-1] + '.wav" type="audio/wav">Your browser does not support the audio tag</audio></td>';
		}
		tr_string += "</tr>"
		$("#" + tbody_id).append(tr_string)
	}
		else {
			var tr_string = '<tr>';
		for(var j = 1; j < techniques.length+1; j++){
			// var text =  transcripts[0][0];
			var row = (i+1)/2;
			console.log(i, row);
			tr_string += '<td>' + transcripts[row-1][j-1]  + '</td>';
		}
		tr_string += "</tr>"
		$("#" + tbody_id).append(tr_string)
	}
		
	}
}


var num_samples = 10;
let tech = ["benign", "AE", "Down-Up", "LPC", "Quant", "ANR", "SNR", "DiffSpec", "DiffWave", "Ours"];

var cw_trans = 
[["play some music", "call my mom","h on mogl","he sud misic","plal some music","plac some music","lasa isac", "place of music", "place of music", "play somusice"],
["play some music", "cancel my alarm"," o mol","is sic","play som music","placsome music","playaac","place so music", "place so music", "playe so music"],
["play some music", "tell me the password","ol","e sud meslyc","tl some ne sor"," play some yeser","lac otinsec", "play some usic", "play some hnusic", "play some usic"],
["play some music", "go to the police"," on mogle","he sud esic","e so thensic","ac some music","play usic"," som newsice", "lay som newsice", "place some music"],
["play some music", "turn off the bluetooth"," wh on mogal","from sudn usic","in of the blusith","fan some music","e sa music","fe of musich", "fe of musich", "play some music"]]

fill_text_table("cw_tbody", tech, cw_trans, "CW", num_samples, 130);


var num_samples = 10;
let tech_qin = ["benign", "AE", "Down-Up", "LPC", "Quant", "ANR", "SNR", "DiffSpec", "DiffWave", "Ours"];

var qin_trans = 
[["to many experts this trend was inevitable", "call my mom","grimaud or poor horrible the lovable","when he experts this trend was inevitable","to many experts this tran was inevitable","to many experts this tran was inevitable","to many experts this was heaven", "camenny experts this trend was inevitable", "to many experts this trend was inevitable", "to many experts this tread was inevitable"],
["to many experts this trend was inevitable", "cancel my alarm","grimaud or poor horrible the lovable","when he experts this trend was inevitable","to many experts this trend was inevitable","to many experts this tran was inevitablec","to many experts this was heaven", "camenny experts this trend was inevitable", "committee experts this trend was inevitable", "to many experts this tread was inevitable"],
["to many experts this trend was inevitable", "tell me the password","koumauakov who powerful the lovable","from six months this train was inevitable","to many expert this tran was inevitable","to many experts this tran was inevitable","to many experts this was applicable", "to experts this trend was inevitable", "to many experts this friend was inevitable", "to many experts this friend was inevitable"],
["to many experts this trend was inevitable", "go to the police","glorical or powerful the love of all","from whom hexburnts this tran was inevitable","to many exb this tran was inevitable","to many experts this trait was inevitable","to many experts this problem", "to experts this trend was inevitable", "to many experts this trend was inevitable","to many experts this tread was inevitable"],
["to many experts this trend was inevitable", "turn off the bluetooth","the voloogul who called all the world of the hall","his parents the strength was inevitable","to many experts this trend was ivitable","to many experts this trait was hippo","many experts this was hippon","to experts this trend was inevitable", "to many experts this trend was inevitable","to many experts this tread was inevitable"]]

fill_text_table("qin_tbody", tech_qin, qin_trans, "QIN", num_samples, 130);

var num_samples = 10;
let sp_qin = ["benign", "AE", "Down-Up", "LPC", "Quant", "ANR", "SNR", "DiffSpec", "DiffWave", "Ours"];

var sp_trans = 
[["jane may earn more money by working hard", "call my mom","call more al more morabole all"," er wor but eb wor ita on","call ma er more money by workhing hard","mr more money by workings mar","i werk i fon", "ald ma er more money by worth you hard", "ald ma er more money by worth you hard", "aed ma earn more money by work you hard"],
["jane may earn more money by working hard", "cancel my alarm","call more al more morabole all"," er wor butebl work ito on","canbac r more money by workhing a hard","mony by workis far","i were ty pan", "caima er more money by worth in hard", "caime er more money by worth ou hard", "cai te eran more money by worth you  hard"],
["jane may earn more money by working hard", "tell me the password","call more al more morabole all"," wor but o wat he a ond","tell ma er or money by working hard","r more money by workins pard","i work is fon", "thely ma er more money by worth ou hard", "thely mae ear more money by worth ou hard", "thenly make earn more money by woring hard"],
["jane may earn more money by working hard", "go to the police","call more al more morabole all"," wor but o wan he a ond","g mor money by working  hard","r more money by workins pard","i werk te fon", "t ma er more money by worth on hard", "te ta er more money by worth ou hard", "te ta earn more money by working hard"],
["jane may earn more money by working hard", "turn off the bluetooth","call more al more morable hall","t beer wore buteble wor in o on","t m er ore money by work ing  hard","s ta erm ore money by workis hart","i work y fon", "the a ma er more money by worth ou hard", "the a ma er more money by worth you hard", "te ay may earn more money by working hard"]]

fill_text_table("sp_tbody", sp_qin, sp_trans, "SP", num_samples, 130);



</script>	


</html>

